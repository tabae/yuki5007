{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "n_parallel = 8\n",
    "n_files = 100\n",
    "\n",
    "def calc_scores():\n",
    "    os.system(\"g++ -O2 -std=c++17 main.cpp -o exe\")\n",
    "    scores = joblib.Parallel(n_jobs=n_parallel) (\n",
    "        joblib.delayed(calc_score_each)(i) for i in range(n_files)\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "def calc_score_each(seed: int):\n",
    "    in_file = f\"input/{seed:04}.txt\"\n",
    "    out_file = f\"output/{seed:04}.txt\"\n",
    "    os.makedirs(\"tools/output\", exist_ok=True)\n",
    "    os.system(f\"./exe < tools/{in_file} > tools/{out_file} 2> /dev/null\")\n",
    "    cmd = f\"cd tools && dotnet tester.dll judge -i {in_file} -o {out_file} 2> /dev/null\"\n",
    "    out = os.popen(cmd)\n",
    "    res = out.read().split()[-1]\n",
    "    print('seed: {}, res: {}'.format(seed, res))\n",
    "    return int(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt = time.time()\n",
    "scores = calc_scores()\n",
    "print(\"elapsed time: {} s\".format(time.time() - srt))\n",
    "print(statistics.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [[] for _ in range(9)]\n",
    "data_y = [[] for _ in range(9)]\n",
    "with open('cluster.txt') as f:\n",
    "    line = f.readline()\n",
    "    while(line):\n",
    "        c, x, y = map(int, line.split())\n",
    "        data_x[c].append(x)\n",
    "        data_y[c].append(y)\n",
    "        line = f.readline()\n",
    "\n",
    "for i in range(9):\n",
    "    plt.scatter(data_x[i], data_y[i], label=str(i))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def calc_scores_op(l_ratio, r_ratio):\n",
    "    os.system(\"g++ -O2 -std=c++17 -DOPTUNA main.cpp -o exe\")\n",
    "    scores = joblib.Parallel(n_jobs=n_parallel) (\n",
    "        joblib.delayed(calc_score_each_op)(i, l_ratio, r_ratio) for i in range(n_files)\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "def calc_score_each_op(seed: int, l_ratio, r_ratio):\n",
    "    in_file = f\"input/{seed:04}.txt\"\n",
    "    out_file = f\"output/{seed:04}.txt\"\n",
    "    os.makedirs(\"tools/output\", exist_ok=True)\n",
    "    os.system(f\"./exe {l_ratio} {r_ratio} < tools/{in_file} > tools/{out_file} 2> /dev/null\")\n",
    "    cmd = f\"cd tools && dotnet tester.dll judge -i {in_file} -o {out_file} 2> /dev/null\"\n",
    "    out = os.popen(cmd)\n",
    "    res = out.read().split()[-1]\n",
    "    #print('seed: {}, res: {}'.format(seed, res))\n",
    "    return int(res)\n",
    "    \n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    start = time.time()\n",
    "    l_ratio = trial.suggest_int(\"climb1\", 1, 100)\n",
    "    r_ratio = trial.suggest_int(\"climb2\", 1, 100)\n",
    "    scores = calc_scores_op(l_ratio, r_ratio)\n",
    "    #print(f\"elapsed: {time.time() - start}\")\n",
    "    return statistics.mean(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        storage=\"sqlite:///mtk005.db\",\n",
    "        study_name=\"tune_range\",\n",
    "        \n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
